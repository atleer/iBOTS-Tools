{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The File object: open()\n",
    "\n",
    "| Command | Purpose |\n",
    "| :-- | :-- |\n",
    "| `file = open(filename, 'r')` |\n",
    "| `file = open(filename, 'w')` |\n",
    "| `text = file.read()` | |\n",
    "| `file.write(text)` | |\n",
    "| `file.close()` |  |\n",
    "| `with open(fname) as file: file.read()` |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionaries can contain any type of data, including other dictionaries!  This makes it straightforward to organize data in multiple levels (i.e. \"hiearchically\").  Let's play around a bit with this experiment's metadata to get a feel for hierarchical keys.  Note that this data also includes lists, which are indexed by position, instead of keys (use integers to indicate whether you want the first, second, or last value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workgroup = {\n",
    "    \"city\": \"Bonn\",\n",
    "    \"name\": \"AG Duggee\",\n",
    "    \"members\": [\n",
    "        {\"name\": \"Rowley\", \"species\": \"Hippo\"},\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDF5 (H5) Files\n",
    "\n",
    "To save RAM: Partial File Reading\n",
    "\n",
    "| Code | Description |\n",
    "| :-- | :-- |\n",
    "| `f = h5py.File(fname, 'w')` | |\n",
    "| `f['a'] = a` |  |\n",
    "| `f['g1/b'] = b` | |\n",
    "| `f = h5py.File(fname)` | |\n",
    "| `f.keys()` | |\n",
    "| `f['a'][:]` | |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"data2/x2.h5\", \"w\")\n",
    "f['a'] = np.arange(5)\n",
    "f['g1/b'] = np.arange(50)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 file \"x2.h5\" (mode r)>\n",
      "[0 1 2 3 4]\n",
      "<KeysViewHDF5 ['a', 'g1']>\n",
      "{'a': <HDF5 dataset \"a\": shape (5,), type \"<i4\">, 'g1': <HDF5 group \"/g1\" (1 members)>}\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File(\"data2/x2.h5\", )\n",
    "print(f)\n",
    "print(f['a'][:])\n",
    "print(f.keys())\n",
    "print(dict(f))\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting Metadata into HDF5 Files\n",
    "\n",
    "| Code | Descrpition |\n",
    "| :-- | :-- |\n",
    "| `f.attrs['x'] = 3` | |\n",
    "| `f['a'].attrs['y'] = 'hello'` | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 []>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.attrs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Formats, Tools, Data Structures, in Neuroscience using HDF5\n",
    "\n",
    "MAT, NetCDF, NWB, NIX, DeepLabCut, PyTables (Fixed and Tabular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (extra) Compression\n",
    "\n",
    "https://docs.h5py.org/en/stable/high/dataset.html#lossless-compression-filters\n",
    "\n",
    "| Code | Description |\n",
    "| :-- | :-- |\n",
    "| `np.savez_compressed(fname, x=x, y=y)` | |\n",
    "| `f.create_dataset('a', data=x)` |  |\n",
    "| `f.create_dataset('a', data=x, compression, compression_opts)` | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (extra) MAT Files\n",
    "\n",
    "| Code | Description |\n",
    "| :-- | :-- |\n",
    "| `savemat(fname, {'x': values})` |  |\n",
    "| `savemat(fname, {'x': x, 'y': y}, do_compression=True)` | |\n",
    "| `loadmat(fname)` |  |\n",
    "| `whosmat(fname)` | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.matlab import savemat, loadmat, whosmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting Tables into a Container Format: Data Formats Using HDF5\n",
    "\n",
    "(exploration using HDFView, using Pandas to handle write/read)\n",
    "\n",
    " - unstructured hdf\n",
    " - netcdf\n",
    "  - pytables\n",
    "    - table\n",
    "    - fixed-format"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "duckdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
